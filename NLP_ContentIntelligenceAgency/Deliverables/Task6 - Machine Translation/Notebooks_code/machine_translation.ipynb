{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-10 13:23:12.731610: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import (\n",
    "    MBartForConditionalGeneration,\n",
    "    MBart50TokenizerFast,\n",
    "    Seq2SeqTrainer,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    EarlyStoppingCallback\n",
    ")\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install transformers[torch] accelerate>=0.26.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining data from OPUS for model training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Russian and English parallel sentence files\n",
    "ru_file = \"TED2020.en-ru.ru\"\n",
    "en_file = \"TED2020.en-ru.en\"\n",
    "output_file = \"TED2020_translations.xlsx\"\n",
    "\n",
    "# Read both files line by line\n",
    "with open(ru_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    ru_sentences = f.readlines()\n",
    "\n",
    "with open(en_file, \"r\", encoding=\"utf-8\") as f:\n",
    "    en_sentences = f.readlines()\n",
    "\n",
    "# Sanity check: Ensure equal number of lines\n",
    "if len(ru_sentences) != len(en_sentences):\n",
    "    print(\"Error: Files contain a different number of lines!\")\n",
    "else:\n",
    "    print(f\"Loaded {len(ru_sentences)} sentence pairs.\")\n",
    "\n",
    "# Create a DataFrame with Russian and English sentences\n",
    "df = pd.DataFrame({\n",
    "    \"Russian\": [s.strip() for s in ru_sentences], \n",
    "    \"English\": [s.strip() for s in en_sentences]\n",
    "})\n",
    "\n",
    "# Save the sentence pairs to an Excel file\n",
    "df.to_excel(output_file, index=False, engine=\"openpyxl\")\n",
    "print(f\"Data successfully saved to '{output_file}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split Data into Train/Validation/Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset\n",
    "df = pd.read_excel(\"TED2020_translations.xlsx\")\n",
    "\n",
    "# Split into training (80%) and temp (20%)\n",
    "train, temp = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Split temp into validation (10%) and test (10%)\n",
    "val, test = train_test_split(temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Save the splits to Excel\n",
    "train.to_excel(\"train.xlsx\", index=False, engine=\"openpyxl\")\n",
    "val.to_excel(\"val.xlsx\", index=False, engine=\"openpyxl\")\n",
    "test.to_excel(\"test.xlsx\", index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(f\"Data prepared and saved: train({len(train)}), val({len(val)}), test({len(test)})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Training and Validation Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and validation data\n",
    "train_data = pd.read_excel(\"train.xlsx\", engine=\"openpyxl\")\n",
    "val_data = pd.read_excel(\"val.xlsx\", engine=\"openpyxl\")\n",
    "\n",
    "# Drop empty rows and ensure all values are strings\n",
    "train_data = train_data.dropna().astype(str)\n",
    "val_data = val_data.dropna().astype(str)\n",
    "\n",
    "# Save cleaned versions (optional for debugging)\n",
    "train_data.to_excel(\"train_cleaned.xlsx\", index=False, engine=\"openpyxl\")\n",
    "val_data.to_excel(\"val_cleaned.xlsx\", index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(\"Data cleaned and saved as 'train_cleaned.xlsx' and 'val_cleaned.xlsx'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tune mBART on Translation Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load cleaned training and validation datasets\n",
    "train_data = pd.read_excel(\"train_cleaned.xlsx\", engine=\"openpyxl\")\n",
    "val_data = pd.read_excel(\"val_cleaned.xlsx\", engine=\"openpyxl\")\n",
    "\n",
    "# Convert to Hugging Face Datasets\n",
    "train_dataset = Dataset.from_pandas(train_data)\n",
    "val_dataset = Dataset.from_pandas(val_data)\n",
    "\n",
    "# Load mBART tokenizer and set language codes\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(\"facebook/mbart-large-50-many-to-many-mmt\")\n",
    "tokenizer.src_lang = \"ru_RU\"\n",
    "tokenizer.tgt_lang = \"en_XX\"\n",
    "\n",
    "# Load the mBART model from a checkpoint\n",
    "model = MBartForConditionalGeneration.from_pretrained(\"mbart_translation_full/checkpoint-9656\")\n",
    "\n",
    "# Tokenization and preprocessing function\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(\n",
    "        examples[\"Russian\"],\n",
    "        text_target=examples[\"English\"],\n",
    "        max_length=128,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\"\n",
    "    )\n",
    "\n",
    "# Tokenize both datasets\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True)\n",
    "val_dataset = val_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "# Set training parameters\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"mbart_translation_full\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=10,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    logging_steps=50,\n",
    "    save_total_limit=1,\n",
    "    predict_with_generate=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False\n",
    ")\n",
    "\n",
    "# Set up Trainer with early stopping\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=2)]\n",
    ")\n",
    "\n",
    "# Resume training from checkpoint\n",
    "trainer.train(resume_from_checkpoint=True)\n",
    "\n",
    "# Save the final trained model and tokenizer\n",
    "model.save_pretrained(\"mbart_translation_full\")\n",
    "tokenizer.save_pretrained(\"mbart_translation_full\")\n",
    "\n",
    "print(\"Training complete. Model saved in 'mbart_translation_full'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Trained mBART Model for Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Excel file with Russian sentences to translate\n",
    "file_path = \"assembly_WER.xlsx\"\n",
    "df = pd.read_excel(file_path, engine=\"openpyxl\")\n",
    "\n",
    "# Validate required column exists\n",
    "if \"Sentence\" not in df.columns:\n",
    "    raise ValueError(\"The file does not contain a 'Sentence' column. Please check the structure.\")\n",
    "\n",
    "# Load trained model and tokenizer\n",
    "model_path = \"mbart_translation_full\"\n",
    "tokenizer = MBart50TokenizerFast.from_pretrained(model_path)\n",
    "model = MBartForConditionalGeneration.from_pretrained(model_path)\n",
    "\n",
    "# Set source and target language codes\n",
    "tokenizer.src_lang = \"ru_RU\"\n",
    "tokenizer.tgt_lang = \"en_XX\"\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "\n",
    "# Define translation function (batched)\n",
    "def batch_translate(sentences, model, tokenizer, num_beams=5):\n",
    "    inputs = tokenizer(sentences, return_tensors=\"pt\", padding=True, truncation=True, max_length=128).to(device)\n",
    "    translated_tokens = model.generate(\n",
    "        **inputs,\n",
    "        num_beams=num_beams,\n",
    "        max_length=128,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    return tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)\n",
    "\n",
    "# Translate sentences in batches\n",
    "batch_size = 16\n",
    "sentences = df[\"Sentence\"].astype(str).tolist()\n",
    "translations = [\n",
    "    translation\n",
    "    for i in range(0, len(sentences), batch_size)\n",
    "    for translation in batch_translate(sentences[i:i + batch_size], model, tokenizer)\n",
    "]\n",
    "\n",
    "# Add translations to DataFrame and save\n",
    "df[\"Translation_mBART\"] = translations\n",
    "output_file = \"translated_assembly_WER_mBART_bean10.xlsx\"\n",
    "df.to_excel(output_file, index=False, engine=\"openpyxl\")\n",
    "\n",
    "print(f\"Translation completed and saved to '{output_file}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
